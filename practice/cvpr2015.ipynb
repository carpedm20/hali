{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  Copy : table: 0x0bc2ba10\n",
       "  ConcatTable : table: 0x0d9521d0\n",
       "  L1HingeEmbeddingCriterion : table: 0x0d970bb0\n",
       "  SpatialAveragePooling : table: 0x0c3db850\n",
       "  StochasticGradient : table: 0x0d982ee0\n",
       "  SpatialConvolutionMM : table: 0x0c3ceb68\n",
       "  Reshape : table: 0x0bc34ed0\n",
       "  SpatialContrastiveNormalization : table: 0x0d93f918\n",
       "  Jacobian : \n",
       "    {\n",
       "      forward : function: 0x0d98a268\n",
       "      testAllUpdate : function: 0x0d989998\n",
       "      testDiagHessianInput : function: 0x0d9898d0\n",
       "      testDiagHessianWeight : function: 0x0d9898f0\n",
       "      testDiagHessianBias : function: 0x0d989910\n",
       "      testDiagHessian : function: 0x0d98a210\n",
       "      testJacobian : function: 0x0d989a60\n",
       "      testIO : function: 0x0d989978\n",
       "      testJacobianUpdateParameters : function: 0x0d989aa0\n",
       "      backwardDiagHessian : function: 0x0d989938\n",
       "      testJacobianParameters : function: 0x0d989a80\n",
       "      backwardUpdate : function: 0x0d98a248\n",
       "      forwardUpdate : function: 0x0d989a40\n",
       "      backward : function: 0x0d98a1f0\n",
       "      linearModuleDiagHessian : function: 0x0d989958\n",
       "    }\n",
       "  CosineEmbeddingCriterion : table: 0x0d9740e8\n",
       "  SparseLinear : table: 0x0bc3a778\n",
       "  CDivTable : table: 0x0bf9f268\n",
       "  Container : table: 0x0bd04bf0\n",
       "  MarginRankingCriterion : table: 0x0d9749f0\n",
       "  test : function: 0x0ba97098\n",
       "  CAddTable : table: 0x0bf9da40\n",
       "  TemporalConvolution : table: 0x0c3de1b0\n",
       "  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "PairwiseDistance : table: 0x0c3a6e70\n",
       "  SpatialLPPooling : table: 0x0c3d97c0\n",
       "  BCECriterion : table: 0x0d97dce0\n",
       "  Concat : table: 0x0bf18040\n",
       "  CrossEntropyCriterion : table: 0x0d97f628\n",
       "  SelectTable : table: 0x0d959878\n",
       "  LookupTable : table: 0x0c3c4628\n",
       "  ParallelTable : table: 0x0d94f6c8\n",
       "  MM : table: 0x0d9856e8\n",
       "  HardShrink : table: 0x0c3bd0f8\n",
       "  TanhShrink : table: 0x0c3b7280\n",
       "  MixtureTable : table: 0x0d95c778\n",
       "  ParallelCriterion : table: 0x0d980d90\n",
       "  Abs : table: 0x0c3b8590\n",
       "  SpatialFullConvolutionMap : table: 0x0c3ccfa8\n",
       "  SparseJacobian : \n",
       "    {\n",
       "      forward : function: 0x0d98caa0\n",
       "      testJacobian : function: 0x0d98ca48\n",
       "      testIO : function: 0x0d98d610\n",
       "      testAllUpdate : function: 0x0d991628\n",
       "      testJacobianParameters : function: 0x0d98d5d0\n",
       "      testJacobianUpdateParameters : function: 0x0d98d5f0\n",
       "      forwardUpdate : function: 0x0d98d638\n",
       "      backward : function: 0x0d98cb38\n",
       "      backwardUpdate : function: 0x0d98ca80\n",
       "    }\n",
       "  LogSoftMax : table: 0x0c3af580\n",
       "  SoftMin : table: 0x0c3b28c8\n",
       "  WeightedMSECriterion : table: 0x0d97bdc0\n",
       "  Min : table: 0x0bf89980\n",
       "  Square : table: 0x0c3bac18\n",
       "  L1Cost : table: 0x0d979648\n",
       "  Exp : table: 0x0c3aaf60\n",
       "  Add : table: 0x0bf965b8\n",
       "  MultiLabelMarginCriterion : table: 0x0d9784d8\n",
       "  MultiMarginCriterion : table: 0x0d977288\n",
       "  HingeEmbeddingCriterion : table: 0x0d9725a8\n",
       "  MarginCriterion : table: 0x0d968d00\n",
       "  DistKLDivCriterion : table: 0x0d96d820\n",
       "  ClassNLLCriterion : table: 0x0d96b678\n",
       "  BatchNormalization : table: 0x0bf41e68\n",
       "  AbsCriterion : table: 0x0d969ec8\n",
       "  FlattenTable : table: 0x0d960a78\n",
       "  MultiCriterion : table: 0x0d96e6d0\n",
       "  PReLU : table: 0x0c3c22a8\n",
       "  utils : \n",
       "    {\n",
       "      recursiveType : function: 0x0bc474b0\n",
       "      recursiveResizeAs : function: 0x0bcfb5b8\n",
       "      recursiveAdd : function: 0x0bd35790\n",
       "      addSingletonDimension : function: 0x0bd357b0\n",
       "      recursiveFill : function: 0x0bc47358\n",
       "    }\n",
       "  AddConstant : table: 0x0bf989d8\n",
       "  Max : table: 0x0bf8aa48\n",
       "  CMul : table: 0x0bf90140\n",
       "  Replicate : table: 0x0bf3f5e8\n",
       "  View : table: 0x0bd0dc00\n",
       "  Mean : table: 0x0bf8d150\n",
       "  MSECriterion : table: 0x0d967a40\n",
       "  Dropout : table: 0x0bf996a0\n",
       "  Criterion : table: 0x0d9658c8\n",
       "  SoftPlus : table: 0x0c3b3b58\n",
       "  Identity : table: 0x0d964170\n",
       "  HardTanh : table: 0x0c3ad300\n",
       "  NarrowTable : table: 0x0d962aa8\n",
       "  Transpose : table: 0x0bf406c0\n",
       "  L1Penalty : table: 0x0d97a978\n",
       "  SplitTable : table: 0x0bf8be78\n",
       "  DotProduct : table: 0x0c3a9e38\n",
       "  Sqrt : table: 0x0c3bbe48\n",
       "  Sequential : table: 0x0bd2ac30\n",
       "  DepthConcat : table: 0x0bd07bb8\n",
       "  CMulTable : table: 0x0bfa04c0\n",
       "  ReLU : table: 0x0c3c0bd0\n",
       "  Parallel : table: 0x0bc5afa8\n",
       "  SoftShrink : table: 0x0c3be318\n",
       "  JoinTable : table: 0x0d958608\n",
       "  VolumetricAveragePooling : table: 0x0d94d958\n",
       "  SoftMax : table: 0x0c3b15a0\n",
       "  SpatialSubtractiveNormalization : table: 0x0d93cac0\n",
       "  VolumetricMaxPooling : table: 0x0d94c338\n",
       "  VolumetricConvolution : table: 0x0d949480\n",
       "  SpatialBatchNormalization : table: 0x0d947060\n",
       "  Log : table: 0x0c3ac280\n",
       "  SpatialUpSamplingNearest : table: 0x0d945bd0\n",
       "  SpatialDropout : table: 0x0bf9b538\n",
       "  Padding : table: 0x0bc2e4d0\n",
       "  Sum : table: 0x0bf8ee98\n",
       "  SoftSign : table: 0x0c3b4a80\n",
       "  SpatialDivisiveNormalization : table: 0x0d9405c0\n",
       "  TemporalMaxPooling : table: 0x0c3e2688\n",
       "  TemporalSubSampling : table: 0x0c3e0290\n",
       "  SpatialAdaptiveMaxPooling : table: 0x0c3dd2e8\n",
       "  Tanh : table: 0x0c3b5ee0\n",
       "  hessian : \n",
       "    {\n",
       "      accDiagHessianParameters : function: 0x0c3d71d8\n",
       "      updateDiagHessianInputPointWise : function: 0x0d94d8a8\n",
       "      initDiagHessianParameters : function: 0x0d94f438\n",
       "      updateDiagHessianInput : function: 0x0d94d930\n",
       "      enable : function: 0x0d974888\n",
       "    }\n",
       "  Linear : table: 0x0bf35ea8\n",
       "  Select : table: 0x0bd10588\n",
       "  SpatialMaxPooling : table: 0x0c3d7838\n",
       "  SpatialSubSampling : table: 0x0c3d5870\n",
       "  tables : \n",
       "    {\n",
       "      full : function: 0x0c3d1638\n",
       "      oneToOne : function: 0x0c3d4030\n",
       "      random : function: 0x0c3d4438\n",
       "    }\n",
       "  SpatialConvolution : table: 0x0c3c6cf8\n",
       "  CriterionTable : table: 0x0d95f0f0\n",
       "  SpatialConvolutionMap : table: 0x0c3d15c0\n",
       "  CSubTable : table: 0x0bfa1658\n",
       "  Power : table: 0x0c3b9a58\n",
       "  Module : table: 0x0bc2f340\n",
       "  Weigh"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tedEuclidean : table: 0x0c3a3540\n",
       "  SpatialFullConvolution : table: 0x0c3c9fc8\n",
       "  CosineDistance : table: 0x0c3a7dc0\n",
       "  Euclidean : table: 0x0bfa3480\n",
       "  SpatialZeroPadding : table: 0x0d942e80\n",
       "  Mul : table: 0x0bf93668\n",
       "  Narrow : table: 0x0bf3d390\n",
       "  Threshold : table: 0x0c3bf9c0\n",
       "  LogSigmoid : table: 0x0c3ae550\n",
       "  Sigmoid : table: 0x0c3b0590\n",
       "  MulConstant : table: 0x0bf94608\n",
       "}\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'nn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "\n",
    "model:add(nn.SpatialConvolution(3,16,5,5))\n",
    "model:add(nn.Tanh())\n",
    "model:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "model:add(nn.SpatialContrastiveNormalization(16,image.gaussian(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 'hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hello\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b[1] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b[2] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : hello\n",
       "  2 : 30\n",
       "}\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\thello\t\n",
       "2\t30\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i=1,#b do\n",
    "    print(i, b[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=torch.Tensor(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.1050e+231 -3.1050e+231  5.4347e-323\n",
       "  0.0000e+00  6.4822e+170  1.5001e+248\n",
       " 4.5062e-144  9.3152e+242   1.1644e-28\n",
       " 1.1443e+243  1.3562e+248  2.7823e+296\n",
       " 9.8006e+252  1.2397e+224  2.2682e+161\n",
       "[torch.DoubleTensor of size 5x3]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.rand(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.4228  0.9625  0.9046\n",
       " 0.1540  0.2256  0.2695\n",
       " 0.3972  0.6424  0.4271\n",
       " 0.7868  0.5481  0.3868\n",
       " 0.4586  0.4077  0.0332\n",
       "[torch.DoubleTensor of size 5x3]\n",
       "\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b=torch.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.8941  0.8477  0.2894  0.2801\n",
       " 0.0080  0.5432  0.8755  0.8565\n",
       " 0.6978  0.0391  0.1075  0.9065\n",
       "[torch.DoubleTensor of size 3x4]\n",
       "\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0170  0.9165  1.0623  1.7628\n",
       " 0.3276  0.2636  0.2711  0.4807\n",
       " 0.6583  0.7023  0.7233  1.0487\n",
       " 0.9778  0.9798  0.7492  1.0405\n",
       " 0.4364  0.6114  0.4932  0.5077\n",
       "[torch.DoubleTensor of size 5x4]\n",
       "\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0170  0.9165  1.0623  1.7628\n",
       " 0.3276  0.2636  0.2711  0.4807\n",
       " 0.6583  0.7023  0.7233  1.0487\n",
       " 0.9778  0.9798  0.7492  1.0405\n",
       " 0.4364  0.6114  0.4932  0.5077\n",
       "[torch.DoubleTensor of size 5x4]\n",
       "\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c=torch.Tensor(5,4)\n",
    "c:mm(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0170  0.9165  1.0623  1.7628\n",
       " 0.3276  0.2636  0.2711  0.4807\n",
       " 0.6583  0.7023  0.7233  1.0487\n",
       " 0.9778  0.9798  0.7492  1.0405\n",
       " 0.4364  0.6114  0.4932  0.5077\n",
       "[torch.DoubleTensor of size 5x4]\n",
       "\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function addTensors(a,b)\n",
    "    return a\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1  1\n",
       " 1  1\n",
       " 1  1\n",
       " 1  1\n",
       " 1  1\n",
       "[torch.DoubleTensor of size 5x2]\n",
       "\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.ones(5,2)\n",
    "b=torch.Tensor(2,5):fill(4)\n",
    "print(addTensors(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4  4  4  4  4\n",
       " 4  4  4  4  4\n",
       "[torch.DoubleTensor of size 2x5]\n",
       "\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lenet5\n",
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]\n",
       "  (1): nn.SpatialConvolution(1 -> 6, 5x5)\n",
       "  (2): nn.SpatialMaxPooling(2,2,2,2)\n",
       "  (3): nn.SpatialConvolution(6 -> 16, 5x5)\n",
       "  (4): nn.SpatialMaxPooling(2,2,2,2)\n",
       "  (5): nn.View\n",
       "  (6): nn.Linear(400 -> 120)\n",
       "  (7): nn.Linear(120 -> 84)\n",
       "  (8): nn.Linear(84 -> 10)\n",
       "  (9): nn.LogSoftMax\n",
       "}\t\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "-- 1 input image channel, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.SpatialConvolution(1,6,5,5))\n",
    "-- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.SpatialConvolution(6,16,5,5))\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "-- reshapes from a 3D tensor of 16x5x5 into 1D\n",
    "net:add(nn.View(16*5*5))\n",
    "-- fully connected layer (matrix multiplication between input and weights)\n",
    "net:add(nn.Linear(16*5*5, 120))\n",
    "net:add(nn.Linear(120, 84))\n",
    "\n",
    "-- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "net:add(nn.Linear(84, 10))\n",
    "-- converts the output to a log-probability. Useful for classification problems\n",
    "net:add(nn.LogSoftMax())\n",
    "\n",
    "print('Lenet5\\n' .. net:__tostring());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lenet5\n",
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]\n",
       "  (1): nn.SpatialConvolution(1 -> 6, 5x5)\n",
       "  (2): nn.SpatialMaxPooling(2,2,2,2)\n",
       "  (3): nn.SpatialConvolution(6 -> 16, 5x5)\n",
       "  (4): nn.SpatialMaxPooling(2,2,2,2)\n",
       "  (5): nn.View\n",
       "  (6): nn.Linear(400 -> 120)\n",
       "  (7): nn.Linear(120 -> 84)\n",
       "  (8): nn.Linear(84 -> 10)\n",
       "  (9): nn.LogSoftMax\n",
       "}\t\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "-- 1 input image channel, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.SpatialConvolution(1,6,5,5))\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.SpatialConvolution(6,16,5,5))\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(16*5*5))\n",
    "net:add(nn.Linear(16*5*5, 120))\n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.Linear(84, 10))\n",
    "net:add(nn.LogSoftMax())\n",
    "print('Lenet5\\n' .. net:__tostring());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=torch.rand(1,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input = torch.rand(1,32,32)\n",
    "\n",
    "output = net:forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.3523\n",
       "-2.2688\n",
       "-2.3015\n",
       "-2.2350\n",
       "-2.2516\n",
       "-2.4362\n",
       "-2.1935\n",
       "-2.3614\n",
       "-2.4636\n",
       "-2.2014\n",
       "[torch.DoubleTensor of size 10]\n",
       "\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3015231333638\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion:forward(output, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lenet5\n",
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> output]\n",
       "  (1): nn.SpatialConvolution(1 -> 6, 5x5)\n",
       "  (2): nn.SpatialMaxPooling(2,2,2,2)\n",
       "  (3): nn.View\n",
       "  (4): nn.Linear(1176 -> 120)\n",
       "  (5): nn.Linear(120 -> 84)\n",
       "  (6): nn.Linear(84 -> 10)\n",
       "  (7): nn.LogSoftMax\n",
       "}\t\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "-- 1 input image channel, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.SpatialConvolution(1,6,5,5))\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(6*14*14))\n",
    "net:add(nn.Linear(6*14*14, 120))\n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.Linear(84, 10))\n",
    "net:add(nn.LogSoftMax())\n",
    "print('Lenet5\\n' .. net:__tostring());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input = torch.rand(1,32,32)\n",
    "\n",
    "output = net:forward(input)\n",
    "gradients = criterion:forward(output, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.1673\n",
       "-2.2890\n",
       "-2.4114\n",
       "-2.3351\n",
       "-2.1905\n",
       "-2.3331\n",
       "-2.3307\n",
       "-2.3276\n",
       "-2.3052\n",
       "-2.3613\n",
       "[torch.DoubleTensor of size 10]\n",
       "\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  1\n",
       " 32\n",
       " 32\n",
       "[torch.LongStorage of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradInput = net:backward(input, torch.rand(10))\n",
    "print(#gradInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,1,.,.) = \n",
       "  0.4253 -0.4710\n",
       " -0.0684 -0.1545\n",
       "\n",
       "(2,1,.,.) = \n",
       "  0.2781  0.1366\n",
       "  0.1528 -0.3866\n",
       "\n",
       "(3,1,.,.) = \n",
       "  0.3166  0.0543\n",
       " -0.4066 -0.1662\n",
       "[torch.DoubleTensor of size 3x1x2x2]\n",
       "\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.SpatialConvolution(1,3,2,2)\n",
    "print(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.4948\n",
       " 0.1610\n",
       "-0.0140\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\texit\t0\t\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.execute('wget -c https://s3.amazonaws.com/torch7/data/cifar10torchsmall.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Archive:  cifar10torchsmall.zip\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "nil\texit\t1\t\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.execute('unzip cifar10torchsmall.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset = torch.load('cifar10-train.t7')\n",
    "testset = torch.load('cifar10-test.t7')\n",
    "classes = {'airplane', 'automobile', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : airplane\n",
       "  2 : automobile\n",
       "  3 : bird\n",
       "  4 : cat\n",
       "  5 : deer\n",
       "  6 : dog\n",
       "  7 : frog\n",
       "  8 : horse\n",
       "  9 : ship\n",
       "  10 : truck\n",
       "}\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  data : ByteTensor - size: 10000x3x32x32\n",
       "  label : ByteTensor - size: 10000\n",
       "}\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 10000\n",
       "     3\n",
       "    32\n",
       "    32\n",
       "[torch.LongStorage of size 4]\n",
       "\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(#trainset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "automobile\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itorch.image(trainset.data[100]) -- display the 100-th image in dataset\n",
    "print(classes[trainset.label[100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- ignore setmetatable for now, it is a feature beyond the scope of this tutorial. It sets the index operator.\n",
    "setmetatable(trainset, \n",
    "    {__index = function(t, i) \n",
    "                    return {t.data[i], t.label[i]} \n",
    "                end}\n",
    ");\n",
    "trainset.data = trainset.data:double() -- convert the data from a ByteTensor to a DoubleTensor.\n",
    "\n",
    "function trainset:size() \n",
    "    return self.data:size(1) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(trainset[2])\n",
    "print(trainset:size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : DoubleTensor - size: 3x32x32\n",
       "  2 : 2\n",
       "}\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(trainset[33]) -- load sample number 33.\n",
    "itorch.image(trainset[33][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redChannel = trainset.data[{ {}, {1}, {}, {}  }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 10000\n",
       "     1\n",
       "    32\n",
       "    32\n",
       "[torch.LongStorage of size 4]\n",
       "\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(#redChannel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : DoubleTensor - size: 6x3x32x32\n",
       "  2 : ByteTensor - size: 6\n",
       "}\n",
       "{\n",
       "  1 : DoubleTensor - size: 1x3x32x32\n",
       "  2 : ByteTensor - size: 1\n",
       "}\n"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainset[{{22,27}}])\n",
    "print(trainset[{{22}}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.5970  0.5784  0.4968  0.4444\n",
       " 0.6418  0.5087  0.6640  0.8520\n",
       " 0.7057  0.3670  0.1674  0.1132\n",
       " 0.3993  0.5957  0.6134  0.5215\n",
       "[torch.DoubleTensor of size 4x4]\n",
       "\n",
       " 0.5970  0.5784  0.4968  0.4444\n",
       "[torch.DoubleTensor of size 1x4]\n",
       "\n",
       " 0.5970  0.5784  0.4968  0.4444\n",
       " 0.6418  0.5087  0.6640  0.8520\n",
       " 0.7057  0.3670  0.1674  0.1132\n",
       "[torch.DoubleTensor of size 3x4]\n",
       "\n",
       " 0.5970\n",
       "[torch.DoubleTensor of size 1x1]\n",
       "\n"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,4)\n",
    "print(a[{}])\n",
    "print(a[{{1}}])\n",
    "print(a[{{1,3}}])\n",
    "print(a[{{1},{1}}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,.,.) = \n",
       "  59\n",
       "[torch.DoubleTensor of size 1x1x1]\n",
       "\n",
       "Channel 1, Mean:125.83175029297\t\n",
       "Channel 1, Mean:63.143400842609\t\n",
       "Channel 2, Mean:123.26066621094\t\n",
       "Channel 2, Mean:62.369209019002\t\n",
       "Channel 3, Mean:114.03068681641\t\n",
       "Channel 3, Mean:66.965808411114\t\n",
       "(1,.,.) = \n",
       " -1.0584\n",
       "[torch.DoubleTensor of size 1x1x1]\n",
       "\n"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = torch.load('cifar10-train.t7')\n",
    "testset = torch.load('cifar10-test.t7')\n",
    "classes = {'airplane', 'automobile', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck'}\n",
    "\n",
    "-- ignore setmetatable for now, it is a feature beyond the scope of this tutorial. It sets the index operator.\n",
    "setmetatable(trainset, \n",
    "    {__index = function(t, i) \n",
    "                    return {t.data[i], t.label[i]} \n",
    "                end}\n",
    ");\n",
    "trainset.data = trainset.data:double() -- convert the data from a ByteTensor to a DoubleTensor.\n",
    "\n",
    "function trainset:size() \n",
    "    return self.data:size(1) \n",
    "end\n",
    "\n",
    "print(trainset[1][1][{{1},{1},{1}}])\n",
    "\n",
    "mean = {}\n",
    "stdv = {}\n",
    "\n",
    "for i=1,3 do\n",
    "    mean[i] = trainset.data[{{},{i},{},{}}]:mean()\n",
    "    print('Channel '..i..', Mean:'..mean[i])\n",
    "    trainset.data[{{},{i},{},{}}]:add(-mean[i])\n",
    "    \n",
    "    stdv[i] = trainset.data[{{},{i},{},{}}]:std()\n",
    "    print('Channel '..i..', Mean:'..stdv[i])\n",
    "    trainset.data[{{},{i},{},{}}]:div(stdv[i])\n",
    "end\n",
    "\n",
    "print(trainset[1][1][{{1},{1},{1}}])\n",
    "\n",
    "testset.data = testset.data:double()\n",
    "for i=1,3 do\n",
    "    testset.data[{{},{i},{},{}}]:add(-mean[i])\n",
    "    testset.data[{{},{i},{},{}}]:div(-stdv[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net:add(nn.SpatialConvolution(3, 6, 5, 5)) -- 3 input image channels, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))     -- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "net:add(nn.SpatialConvolution(6, 16, 5, 5))\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(16*5*5))                    -- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "net:add(nn.Linear(16*5*5, 120))             -- fully connected layer (matrix multiplication between input and weights)\n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.Linear(84, 10))                   -- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "net:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer = nn.StochasticGradient(net, criterion)\n",
    "trainer.learningRate = 0.001\n",
    "trainer.maxIteration = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.9792283812802\t\n"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.6744328943918\t\n"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.5519469537007\t\n"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.4742466806615\t\n"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.414904795588\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 1.414904795588\t\n",
       "\n"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer:train(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "horse\t\n"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classes[testset.label[100]])\n",
    "itorch.image(testset.data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- for fun, print the mean and standard-deviation of example-100\n",
    "horse = testset.data[100]\n",
    "print(horse:mean(), horse:std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8\t\n",
       "horse\t\n"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(testset.label[100])\n",
    "print(classes[testset.label[100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "itorch.image(testset.data[100])\n",
    "predicted = net:forward(testset.data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- the output of the network is Log-Probabilities. To convert them to probabilities, you have to take e^x \n",
    "print(predicted:exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airplane\t0.013486350893839\t\n",
       "automobile\t0.054734149855618\t\n",
       "bird\t0.17365575962472\t\n",
       "cat\t0.22674075713967\t\n",
       "deer\t0.023638286776331\t\n",
       "dog\t0.13306334734964\t\n",
       "frog\t0.33553574979018\t\n",
       "horse\t0.0018922295635312\t\n",
       "ship\t0.02018706528905\t\n",
       "truck\t0.017032957307677\t\n"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i=1,predicted:size(1) do\n",
    "    print(classes[i], predicted[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(predicted:size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i=1,10000 do\n",
    "    local groundtruth = testset.label[i]\n",
    "    local prediction = net:forward(testset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)\n",
    "    if groundtruth==indices[1] then\n",
    "        correct = correct + 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(correct, 100*correct/10000 .. ' % ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_performance = {0,0,0,0,0,0,0,0,0,0}\n",
    "for i=1,10000 do\n",
    "    local groundtruth = testset.label[i]\n",
    "    local prediction = net:forward(testset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)\n",
    "    if groundtruth==indices[1] then\n",
    "        class_performance[groundtruth] =  class_performance[groundtruth] + 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i=1,#class_performance do\n",
    "    print(classes[i], 100*class_performance[i]/1000 .. ' %')\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20003"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
